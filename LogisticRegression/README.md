## 로지스틱 회귀분석

### cleansing.r

* 분석에 필요 없는 feature 제거

```r
# 의미 없는 값이거나 (예: 년도나 ID) 
# 분석이 어려운, 패턴이 없는 문자열 값인 경우 (예: BM14_2, 구강 진료를 받지 못한 상세 이유) 제거

# 결측치가 2000 이상인 열 제거
# 결측치가 포함된 행 제거

# 결과
dim(cleaned_data)
# [1] 1614  578
```



### feature_engineering.r

* 앞서 한 차례 feature를 제거했음에도 feature가 너무 많음(600개 가량)

* 차원의 저주 현상이 일어날 수 있으므로 feature selection이 필요함

  

* 로지스틱 회귀 모델(glm())로 Wrapper 방법 중 하나인 Forward Selection(전진 선택) 진행

  ```r
  # 결과
  dim(selected_data)
  # [1] 2699   65
  > glimpse(selected_data)
  # Rows: 1,614
  # Columns: 68
  # $ age          <int> 78, 80, 57, 27, 26, 58, 80, 73, 77, 34, 74, 38, 36, 71,…
  # $ sex          <int> 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2…
  # $ BP_PHQ_5     <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0…
  # $ L_DN         <int> 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BS3_3        <int> 88, 88, 88, 3, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, …
  # $ BS12_31      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BD7_5        <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…
  # $ BA1_3        <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ N_VA_RAE     <dbl> 197.53751, 48.43013, 350.03877, 80.73484, 198.06009, 16…
  # $ DH2_dg       <int> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BP_PHQ_6     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0…
  # $ DI1_pt       <int> 8, 8, 8, 8, 8, 1, 1, 8, 1, 8, 0, 8, 8, 1, 8, 1, 1, 8, 8…
  # $ DJ2_dg       <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ DI6_pt       <int> 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DI6_ag       <int> 888, 888, 40, 888, 888, 888, 888, 888, 888, 888, 888, 8…
  # $ DI3_2        <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ allownc      <int> 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,…
  # $ BA2_13       <int> 5, 5, 4, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5…
  # $ DC3_ag       <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ HE_Uket      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ HE_Uph       <dbl> 5.5, 5.0, 7.5, 5.5, 6.5, 6.0, 7.5, 5.0, 5.5, 5.5, 7.5, …
  # $ ainc_1       <int> 1500, 908, 1500, 1500, 1500, 200, 540, 540, 107, 9700, …
  # $ BE3_33       <int> 0, 30, 0, 30, 0, 0, 0, 40, 88, 30, 88, 88, 0, 0, 30, 30…
  # $ HE_DMfh3     <int> 0, 9, 0, 0, 0, 0, 1, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 0, 0…
  # $ HE_Uro       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ DH6_ag       <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ DH6_pt       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BM13_1       <int> 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BE3_31       <int> 4, 4, 8, 4, 8, 8, 8, 4, 1, 8, 1, 1, 3, 3, 7, 5, 8, 7, 4…
  # $ BD2_14       <int> 888, 888, 888, 16, 10, 888, 888, 888, 888, 888, 888, 88…
  # $ HE_Upro      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0…
  # $ DE1_pt       <int> 8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DE1_pr       <int> 8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BP7          <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…
  # $ BP16_23      <int> 6, 7, 8, 8, 12, 7, 5, 6, 5, 9, 7, 5, 9, 4, 8, 7, 7, 9, …
  # $ BP16_21      <int> 23, 24, 23, 24, 2, 24, 21, 22, 24, 1, 21, 1, 24, 21, 24…
  # $ BP_PHQ_7     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ T_Q_HR1      <int> 8, 8, 3, 8, 8, 8, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DE2_dg       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ npins        <int> 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1…
  # $ OR1_2        <int> 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0…
  # $ edu          <int> 4, 1, 3, 4, 3, 4, 4, 4, 2, 4, 1, 3, 4, 1, 4, 3, 2, 4, 3…
  # $ EC_pedu_2    <int> 88, 88, 2, 5, 5, 5, 88, 88, 88, 5, 88, 3, 5, 88, 7, 3, …
  # $ HE_hsCRP     <dbl> 3.53, 0.74, 1.83, 0.87, 0.37, 0.51, 4.08, 0.62, 0.19, 5…
  # $ DC2_dg       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ HE_UCREA     <dbl> 100.1, 67.3, 78.5, 169.3, 87.1, 67.9, 68.5, 100.5, 136.…
  # $ LQ2_mn       <int> 88, 88, 2, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, …
  # $ BA2_2_4      <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ Total_slp_wd <int> 420, 450, 570, 480, 600, 420, 450, 480, 300, 480, 600, …
  # $ BP16_22      <int> 0, 0, 0, 0, 0, 0, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
  # $ BP_PHQ_9     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0…
  # $ BA2_22       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
  # $ HE_DMdg      <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BE3_76       <int> 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BE3_78       <int> 88, 88, 88, 88, 30, 88, 88, 88, 88, 88, 88, 88, 88, 88,…
  # $ BH1          <int> 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2…
  # $ BM2_2        <int> 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…
  # $ DJ8_pt       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0…
  # $ DJ8_pr       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0…
  # $ L_BR_WHO     <int> 1, 1, 1, 1, 8, 1, 1, 1, 1, 8, 8, 2, 8, 1, 8, 8, 8, 8, 1…
  # $ DF2_pr       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DI1_2        <int> 8, 8, 8, 8, 8, 1, 2, 8, 1, 8, 5, 8, 8, 1, 8, 1, 1, 8, 8…
  # $ mh_stress    <int> 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BE8_2        <int> 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
  # $ BP2          <int> 88, 88, 1, 9, 6, 4, 88, 88, 4, 2, 88, 88, 4, 9, 2, 3, 8…
  # $ T_NQ_OCP_T   <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ HE_fst       <int> 13, 11, 12, 13, 13, 14, 13, 13, 14, 13, 15, 15, 15, 14,…
  # $ danger       <int> 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…
  ```

  

* 설문조사 결과가 "모름" 인 경우를 missing value로 간주하고 대체

  * numerical variable은 평균값, categorical variable은 최빈값으로 대체

  

* 다중공선성이 높은 feature들 제거

  ```r
   vif(glm_fit)
  
  # DI1_pt	2.67E+01	고혈압 치료
  # DI1_2     2.71E+01	혈압조절제 복용 -> 제거
  # DI6_pt	8.69E+08	협심증 치료
  # DI6_ag	8.69E+08	협심증 진단시기 -> 제거
  # DH6_pt	2.38E+02	황반변성 치료
  # DH6_ag	2.38E+02	황반변성 진단시기 -> 제거
  # DE1_pt	9.70E+09	당뇨병 치료
  # DE1_pr	9.70E+09	당뇨병현재유병여부 -> 제거
  # HE_DMdg	4.80E+01	당뇨병 의사진단 여부 -> 제거
  # DJ8_pt	2.01E+02	알레르기비염 치료
  # DJ8_pr	2.00E+02	알레르기비염 현재 유병 여부 -> 제거
  ```

  

* 클래스 불균형 데이터 문제 해결 위해 언더 샘플링 진행

  ```r
  table(selected_data$danger)
  #    0    1 
  #  487 1127 
  
  # ...
  
  # 결과
  table(selected_data$danger)
  #   0   1 
  # 480 480 
  dim(selected_data)
  # [1] 960  58
  ```



### modeling.r

* 분석에 앞서 train, test 데이터세트 나눔

  ```r
  dim(train_dataset)
  # [1] 768  62
  dim(test_dataset)
  # [1] 192  62
  ```

* embedded 기법인 lasso 모델링

  * 최적의 lambda 값을 찾기 위해 교차검증

  * cv.glmnet() 사용

    ```r
    lasso_model <- cv.glmnet( x=data.matrix(train_dataset[,-length(train_dataset)]), y = train_dataset[,length(train_dataset)],
    family = "binomial" , type.measure = "auc",alpha=1, nfolds=5)
    
    print(lasso_model)
    #       Lambda Measure
    # min 0.000974  0.7609
    # 1se 0.006870  0.7505
    
    plot(lasso_model)
    ```

    <img src="https://user-images.githubusercontent.com/46865281/81467885-a0077300-9216-11ea-92fe-a209cf252799.png" width="500" height="500">

* lasso 모형 선택 결과

  * 오컴의 면도날(Occam’s razor)법칙에 의거해 1-표준편차 범위에서의 lambda 값으로 lasso 회귀 모형을 구축

  ```r
  coef(lasso_model, s=lasso_model$lambda.1se)
  # 62 x 1 sparse Matrix of class "dgCMatrix"
  #                          1
  # (Intercept)   1.785289e-01
  # age          -3.386398e-02
  # sex           7.789862e-01
  # BP_PHQ_5      1.795264e-01
  # L_DN          6.769563e-01
  # BS3_3         9.540215e-03
  # BS12_31       2.083729e+00
  # BD7_5         6.623972e-01
  # BA1_3        -4.387191e-02
  # N_VA_RAE      .           
  # DH2_dg       -2.606102e-01
  # BP_PHQ_6      2.014826e-01
  # DI1_pt        5.921844e-02
  # DJ2_dg       -1.415856e+00
  # DI6_pt        2.261144e-01
  # DI3_2        -1.054367e-01
  # allownc       .           
  # BA2_13       -1.281884e-01
  # DC3_ag        2.090414e-03
  # HE_Uket      -5.540785e-01
  # HE_Uph       -1.682141e-01
  # ainc_1       -2.663798e-05
  # BE3_33       -7.354934e-03
  # HE_DMfh3      .           
  # HE_Uro       -5.265275e-01
  # DH6_pt       -1.181475e-01
  # BM13_1       -4.012821e-02
  # BE3_31       -5.578935e-02
  # BD2_14       -1.471718e-04
  # HE_Upro       3.484368e-02
  # DE1_pt        7.220648e-02
  # BP7           .           
  # BP16_23      -8.684099e-02
  # BP16_21      -6.858476e-03
  # BP_PHQ_7     -2.201851e-01
  # T_Q_HR1       7.056406e-02
  # DE2_dg        5.970471e-01
  # npins        -3.361607e-01
  # OR1_2        -2.031938e-01
  # edu           1.989401e-01
  # EC_pedu_2     6.891571e-04
  # HE_hsCRP     -1.678640e-02
  # DC2_dg        1.811893e+00
  # HE_UCREA      .           
  # LQ2_mn        .           
  # BA2_2_4      -8.612346e-04
  # Total_slp_wd  1.777133e-04
  # BP16_22       3.962632e-03
  # BP_PHQ_9     -8.371313e-02
  # BA2_22       -2.884229e-02
  # BE3_76       -8.513341e-02
  # BE3_78        7.572839e-04
  # BH1           2.222646e-01
  # BM2_2         .           
  # DJ8_pt        1.664835e-02
  # L_BR_WHO      1.650758e-02
  # DF2_pr       -8.215569e-02
  # mh_stress     2.173938e-01
  # BE8_2        -3.056252e-03
  # BP2           1.590743e-04
  # T_NQ_OCP_T    .           
  # HE_fst       -2.050829e-02
  ```

  

* 평가

  * confusion matrix

    ```r
    lasso_pred <- predict(lasso_model, newx=data.matrix(test_dataset[,-length(test_dataset)]),
                          s=lasso_model$lambda.1se, type= "class", levels=c(1,0))
    
    confusionMatrix(table(factor(test_dataset[,length(test_dataset)], levels=c(1,0)),factor((lasso_pred), levels = c(1,0))))
         
    #      1  0
    #   1 66 30
    #   0 33 63                                          
    #                Accuracy : 0.6719          
    #                  95% CI : (0.6006, 0.7378)
    #     No Information Rate : 0.5156          
    #     P-Value [Acc > NIR] : 8.289e-06       
                                              
    #                   Kappa : 0.3438          
                                              
    #  Mcnemar's Test P-Value : 0.8011          
                                              
    #             Sensitivity : 0.6667          
    #             Specificity : 0.6774          
    #          Pos Pred Value : 0.6875          
    #          Neg Pred Value : 0.6562          
    #              Prevalence : 0.5156          
    #          Detection Rate : 0.3438          
    #    Detection Prevalence : 0.5000          
  #       Balanced Accuracy : 0.6720                                         
    #        'Positive' Class : 1              
  ```
  
    
  
  * ROC curve 및 auc

    ```r
  performance(pred_glment, "auc")@y.values[[1]]
    # [1] 0.7307943
    ```
  
    ​    <img src="https://user-images.githubusercontent.com/46865281/81467930-01c7dd00-9217-11ea-908e-59cc780d6270.png" width="500" height="500">
  
    

