## 로지스틱 회귀분석

### cleansing.r

* 분석에 필요 없는 feature 제거

```r
# 의미 없는 값이거나 (예: 년도나 ID) 
# 분석이 어려운, 패턴이 없는 문자열 값인 경우 (예: BM14_2, 구강 진료를 받지 못한 상세 이유) 제거

# 결측치가 2000 이상인 열 제거
# 결측치가 포함된 행 제거

# 결과
dim(cleaned_data)
# [1] 1614  578
```



### feature_engineering.r

* 앞서 한 차례 feature를 제거했음에도 feature가 너무 많음(600개 가량)

* 차원의 저주 현상이 일어날 수 있으므로 feature selection이 필요함

  

* 로지스틱 회귀 모델(glm())로 Wrapper 방법 중 하나인 Forward Selection(전진 선택) 진행

  ```r
  # 결과
  dim(selected_data)
  # [1] 2699   65
  > glimpse(selected_data)
  # Rows: 1,614
  # Columns: 68
  # $ age          <int> 78, 80, 57, 27, 26, 58, 80, 73, 77, 34, 74, 38, 36, 71,…
  # $ sex          <int> 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2…
  # $ BP_PHQ_5     <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0…
  # $ L_DN         <int> 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BS3_3        <int> 88, 88, 88, 3, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, …
  # $ BS12_31      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BD7_5        <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…
  # $ BA1_3        <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ N_VA_RAE     <dbl> 197.53751, 48.43013, 350.03877, 80.73484, 198.06009, 16…
  # $ DH2_dg       <int> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BP_PHQ_6     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0…
  # $ DI1_pt       <int> 8, 8, 8, 8, 8, 1, 1, 8, 1, 8, 0, 8, 8, 1, 8, 1, 1, 8, 8…
  # $ DJ2_dg       <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ DI6_pt       <int> 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DI6_ag       <int> 888, 888, 40, 888, 888, 888, 888, 888, 888, 888, 888, 8…
  # $ DI3_2        <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ allownc      <int> 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,…
  # $ BA2_13       <int> 5, 5, 4, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5…
  # $ DC3_ag       <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ HE_Uket      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ HE_Uph       <dbl> 5.5, 5.0, 7.5, 5.5, 6.5, 6.0, 7.5, 5.0, 5.5, 5.5, 7.5, …
  # $ ainc_1       <int> 1500, 908, 1500, 1500, 1500, 200, 540, 540, 107, 9700, …
  # $ BE3_33       <int> 0, 30, 0, 30, 0, 0, 0, 40, 88, 30, 88, 88, 0, 0, 30, 30…
  # $ HE_DMfh3     <int> 0, 9, 0, 0, 0, 0, 1, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 0, 0…
  # $ HE_Uro       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ DH6_ag       <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ DH6_pt       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BM13_1       <int> 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BE3_31       <int> 4, 4, 8, 4, 8, 8, 8, 4, 1, 8, 1, 1, 3, 3, 7, 5, 8, 7, 4…
  # $ BD2_14       <int> 888, 888, 888, 16, 10, 888, 888, 888, 888, 888, 888, 88…
  # $ HE_Upro      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0…
  # $ DE1_pt       <int> 8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DE1_pr       <int> 8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BP7          <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…
  # $ BP16_23      <int> 6, 7, 8, 8, 12, 7, 5, 6, 5, 9, 7, 5, 9, 4, 8, 7, 7, 9, …
  # $ BP16_21      <int> 23, 24, 23, 24, 2, 24, 21, 22, 24, 1, 21, 1, 24, 21, 24…
  # $ BP_PHQ_7     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ T_Q_HR1      <int> 8, 8, 3, 8, 8, 8, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DE2_dg       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ npins        <int> 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1…
  # $ OR1_2        <int> 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0…
  # $ edu          <int> 4, 1, 3, 4, 3, 4, 4, 4, 2, 4, 1, 3, 4, 1, 4, 3, 2, 4, 3…
  # $ EC_pedu_2    <int> 88, 88, 2, 5, 5, 5, 88, 88, 88, 5, 88, 3, 5, 88, 7, 3, …
  # $ HE_hsCRP     <dbl> 3.53, 0.74, 1.83, 0.87, 0.37, 0.51, 4.08, 0.62, 0.19, 5…
  # $ DC2_dg       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ HE_UCREA     <dbl> 100.1, 67.3, 78.5, 169.3, 87.1, 67.9, 68.5, 100.5, 136.…
  # $ LQ2_mn       <int> 88, 88, 2, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, …
  # $ BA2_2_4      <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ Total_slp_wd <int> 420, 450, 570, 480, 600, 420, 450, 480, 300, 480, 600, …
  # $ BP16_22      <int> 0, 0, 0, 0, 0, 0, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
  # $ BP_PHQ_9     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0…
  # $ BA2_22       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
  # $ HE_DMdg      <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BE3_76       <int> 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ BE3_78       <int> 88, 88, 88, 88, 30, 88, 88, 88, 88, 88, 88, 88, 88, 88,…
  # $ BH1          <int> 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2…
  # $ BM2_2        <int> 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…
  # $ DJ8_pt       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0…
  # $ DJ8_pr       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0…
  # $ L_BR_WHO     <int> 1, 1, 1, 1, 8, 1, 1, 1, 1, 8, 8, 2, 8, 1, 8, 8, 8, 8, 1…
  # $ DF2_pr       <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…
  # $ DI1_2        <int> 8, 8, 8, 8, 8, 1, 2, 8, 1, 8, 5, 8, 8, 1, 8, 1, 1, 8, 8…
  # $ mh_stress    <int> 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…
  # $ BE8_2        <int> 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
  # $ BP2          <int> 88, 88, 1, 9, 6, 4, 88, 88, 4, 2, 88, 88, 4, 9, 2, 3, 8…
  # $ T_NQ_OCP_T   <int> 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, 888, …
  # $ HE_fst       <int> 13, 11, 12, 13, 13, 14, 13, 13, 14, 13, 15, 15, 15, 14,…
  # $ danger       <int> 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…
  ```

  

* 설문조사 결과가 "모름" 인 경우를 missing value로 간주하고 대체

  * numerical variable은 평균값, categorical variable은 최빈값으로 대체

  

* 다중공선성이 높은 feature들 제거

  ```r
   vif(glm_fit)
  
  # DI1_pt	2.67E+01	고혈압 치료
  # DI1_2     2.71E+01	혈압조절제 복용 -> 제거
  # DI6_pt	8.69E+08	협심증 치료
  # DI6_ag	8.69E+08	협심증 진단시기 -> 제거
  # DH6_pt	2.38E+02	황반변성 치료
  # DH6_ag	2.38E+02	황반변성 진단시기 -> 제거
  # DE1_pt	9.70E+09	당뇨병 치료
  # DE1_pr	9.70E+09	당뇨병현재유병여부 -> 제거
  # HE_DMdg	4.80E+01	당뇨병 의사진단 여부 -> 제거
  # DJ8_pt	2.01E+02	알레르기비염 치료
  # DJ8_pr	2.00E+02	알레르기비염 현재 유병 여부 -> 제거
  ```

  

* 클래스 불균형 데이터 문제 해결 위해 언더 샘플링 진행

  ```r
  table(selected_data$danger)
  #    0    1 
  #  487 1127 
  
  # ...
  
  # 결과
  table(selected_data$danger)
  #   0   1 
  # 480 480 
  dim(selected_data)
  # [1] 960  58
  ```



### modeling.r

* 분석에 앞서 train, test 데이터세트 나눔

  ```r
  dim(train_dataset)
  # [1] 768  62
  dim(test_dataset)
  # [1] 192  62
  ```

* embedded 기법인 lasso 모델링

  * cv.glmnet() 사용
  * alpha =1, nfolds =5, type measure = auc
  * lasso 로지스틱 회귀 분석, 교차검증

* 평가

  * confusion matrix

    ```r
    lasso_pred <- predict(lasso_model, newx=data.matrix(test_dataset[,-length(test_dataset)]),
                          s=lasso_model$lambda.min, type= "class", levels=c(1,0))
    
    confusionMatrix(table(factor(test_dataset[,length(test_dataset)], levels=c(1,0)),factor((lasso_pred), levels = c(1,0))))
         
    #      1  0
    #   1 68 28
    #   0 26 70             
    #                Accuracy : 0.7188          
    #                  95% CI : (0.6495, 0.7811)
    #     No Information Rate : 0.5104          
    #     P-Value [Acc > NIR] : 3.25e-09               
    #                   Kappa : 0.4375          
    #  Mcnemar's Test P-Value : 0.8918          
    #             Sensitivity : 0.7234          
    #             Specificity : 0.7143          
    #          Pos Pred Value : 0.7083          
    #          Neg Pred Value : 0.7292          
    #              Prevalence : 0.4896          
    #          Detection Rate : 0.3542          
    #    Detection Prevalence : 0.5000          
    #       Balanced Accuracy : 0.7188          
    #        'Positive' Class : 1    
    ```

  * roc curve 및 auc

    ```r
    performance(pred_glment, "auc")@y.values[[1]]
    # [1] 0.7203776
    ```

    ![title](https://user-images.githubusercontent.com/46865281/81317716-26fa0580-90c8-11ea-968a-f028464460d0.png){: width="300" height="300"}

    

    